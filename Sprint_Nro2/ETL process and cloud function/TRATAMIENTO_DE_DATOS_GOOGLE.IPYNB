{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer archivo:\n",
      "               name                                            address  \\\n",
      "0   Porter Pharmacy  Porter Pharmacy, 129 N Second St, Cochran, GA ...   \n",
      "1      City Textile  City Textile, 3001 E Pico Blvd, Los Angeles, C...   \n",
      "2      San Soo Dang  San Soo Dang, 761 S Vermont Ave, Los Angeles, ...   \n",
      "3      Nova Fabrics  Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...   \n",
      "4  Nobel Textile Co  Nobel Textile Co, 719 E 9th St, Los Angeles, C...   \n",
      "\n",
      "                                 gmap_id description   latitude   longitude  \\\n",
      "0  0x88f16e41928ff687:0x883dad4fd048e8f8        None  32.388300  -83.357100   \n",
      "1  0x80c2c98c0e3c16fd:0x29ec8a728764fdf9        None  34.018891 -118.215290   \n",
      "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49        None  34.058092 -118.292130   \n",
      "3   0x80c2c89923b27a41:0x32041559418d447        None  34.023669 -118.232930   \n",
      "4  0x80c2c632f933b073:0xc31785961fe826a6        None  34.036694 -118.249421   \n",
      "\n",
      "                category  avg_rating  num_of_reviews price  \\\n",
      "0           ['Pharmacy']         4.9              16  None   \n",
      "1   ['Textile exporter']         4.5               6  None   \n",
      "2  ['Korean restaurant']         4.4              18  None   \n",
      "3       ['Fabric store']         3.3               6  None   \n",
      "4       ['Fabric store']         4.3               7  None   \n",
      "\n",
      "                                               hours  \\\n",
      "0  [['Friday', '8AM–6PM'], ['Saturday', '8AM–12PM...   \n",
      "1                                               None   \n",
      "2  [['Thursday', '6:30AM–6PM'], ['Friday', '6:30A...   \n",
      "3  [['Thursday', '9AM–5PM'], ['Friday', '9AM–5PM'...   \n",
      "4  [['Thursday', '9AM–5PM'], ['Friday', '9AM–5PM'...   \n",
      "\n",
      "                                                MISC              state  \\\n",
      "0  {'Service options': ['In-store shopping', 'Sam...  Open ⋅ Closes 6PM   \n",
      "1                                               None           Open now   \n",
      "2  {'Service options': ['Takeout', 'Dine-in', 'De...  Open ⋅ Closes 6PM   \n",
      "3  {'Service options': ['In-store shopping'], 'Pa...  Open ⋅ Closes 5PM   \n",
      "4           {'Service options': ['In-store pickup']}  Open ⋅ Closes 5PM   \n",
      "\n",
      "                                    relative_results  \\\n",
      "0  ['0x88f16e41929435cf:0x5b2532a2885e9ef6', '0x8...   \n",
      "1  ['0x80c2c624136ea88b:0xb0315367ed448771', '0x8...   \n",
      "2  ['0x80c2c78249aba68f:0x35bf16ce61be751d', '0x8...   \n",
      "3  ['0x80c2c8811477253f:0x23a8a492df1918f7', '0x8...   \n",
      "4  ['0x80c2c62c496083d1:0xdefa11317fe870a1', '0x8...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "1  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "2  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "3  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "4  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "\n",
      "Segundo archivo:\n",
      "                 user_id               name           time  rating  \\\n",
      "0  103491398894836293969  Lupita Diaz Vlogs  1572837129221       5   \n",
      "1  111483590325755644845        Mari Guzmán  1567150590245       5   \n",
      "2  100292508085338293603   Natalie Villegas  1546918794462       5   \n",
      "3  117777929328527840637    nancy la chepis  1548909985440       5   \n",
      "4  117975537997666004204      Lourdes Trejo  1620712549313       5   \n",
      "\n",
      "                                                text  pics  resp  \\\n",
      "0  (Translated by Google) Mass on Sundays at 12:3...  None  None   \n",
      "1  (Translated by Google) Excellent\\n\\n(Original)...  None  None   \n",
      "2                                               None  None  None   \n",
      "3                                               None  None  None   \n",
      "4                                               None  None  None   \n",
      "\n",
      "                                 gmap_id  \n",
      "0  0x809531ea539bb63d:0x13ff4191fb581641  \n",
      "1  0x809531ea539bb63d:0x13ff4191fb581641  \n",
      "2  0x809531ea539bb63d:0x13ff4191fb581641  \n",
      "3  0x809531ea539bb63d:0x13ff4191fb581641  \n",
      "4  0x809531ea539bb63d:0x13ff4191fb581641  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del primer archivo Parquet\n",
    "file_path1 = 'metadatacruda.parquet'\n",
    "\n",
    "# Ruta del segundo archivo Parquet\n",
    "file_path2 = 'REVIEWS_concatenados.parquet'\n",
    "\n",
    "# Leer los archivos Parquet como DataFrames\n",
    "metadata = pd.read_parquet(file_path1)\n",
    "reviews_google = pd.read_parquet(file_path2)\n",
    "\n",
    "# Mostrar las primeras filas de ambos DataFrames\n",
    "print(\"Primer archivo:\")\n",
    "print(metadata.head())\n",
    "\n",
    "print(\"\\nSegundo archivo:\")\n",
    "print(reviews_google.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MUESTRAS PARA LUEGO MOSTRAR LA CARGA DE NEUVOS DATOS CON EL PROCESO ETL AUTOMATIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra del 35% de metadata guardada en: muestra_35_porcentaje_metadata.parquet\n",
      "Muestra del 35% de reviews_google guardada en: muestra_35_porcentaje_reviews_google.parquet\n"
     ]
    }
   ],
   "source": [
    "# Extraer el 35% aleatorio de cada DataFrame\n",
    "sample_metadata = metadata.sample(frac=0.35, random_state=42)\n",
    "sample_reviews_google = reviews_google.sample(frac=0.35, random_state=42)\n",
    "\n",
    "# Guardar las muestras en archivos Parquet\n",
    "sample_file_path1 = 'muestra_35_porcentaje_metadata.parquet'\n",
    "sample_file_path2 = 'muestra_35_porcentaje_reviews_google.parquet'\n",
    "\n",
    "sample_metadata.to_parquet(sample_file_path1)\n",
    "sample_reviews_google.to_parquet(sample_file_path2)\n",
    "\n",
    "print(f\"Muestra del 35% de metadata guardada en: {sample_file_path1}\")\n",
    "print(f\"Muestra del 35% de reviews_google guardada en: {sample_file_path2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el 65% restante de cada DataFrame\n",
    "metadata_g1_google = metadata.drop(sample_metadata.index)\n",
    "reviews_g1_google = reviews_google.drop(sample_reviews_google.index)\n",
    "\n",
    "# Aplicar las transformaciones necesarias sobre el 90% restante\n",
    "# Aquí puedes continuar con tus operaciones de limpieza y transformación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las muestras en archivos Parquet\n",
    "sample_file_path1 = 'metadata_cruda_65%_google.parquet'\n",
    "sample_file_path2 = 'reviews__crudos_65%_google.parquet'\n",
    "\n",
    "metadata_g1_google.to_parquet(sample_file_path1)\n",
    "reviews_g1_google.to_parquet(sample_file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filtrare el dataset por los estados con los que trabajare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        name  \\\n",
      "2                               San Soo Dang   \n",
      "3                               Nova Fabrics   \n",
      "4                           Nobel Textile Co   \n",
      "6                               Vons Chicken   \n",
      "13  Black Tie Ski Rental Delivery of Mammoth   \n",
      "\n",
      "                                              address  \\\n",
      "2   San Soo Dang, 761 S Vermont Ave, Los Angeles, ...   \n",
      "3   Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...   \n",
      "4   Nobel Textile Co, 719 E 9th St, Los Angeles, C...   \n",
      "6   Vons Chicken, 12740 La Mirada Blvd, La Mirada,...   \n",
      "13  Black Tie Ski Rental Delivery of Mammoth, 501 ...   \n",
      "\n",
      "                                  gmap_id description   latitude   longitude  \\\n",
      "2   0x80c2c778e3b73d33:0xbdc58662a4a97d49        None  34.058092 -118.292130   \n",
      "3    0x80c2c89923b27a41:0x32041559418d447        None  34.023669 -118.232930   \n",
      "4   0x80c2c632f933b073:0xc31785961fe826a6        None  34.036694 -118.249421   \n",
      "6   0x80dd2b4c8555edb7:0xfc33d65c4bdbef42        None  33.916402 -118.010855   \n",
      "13  0x80960c29f2e3bf29:0x4b291f0d275a5699        None  37.638754 -118.966055   \n",
      "\n",
      "                                             category  avg_rating  \\\n",
      "2                               ['Korean restaurant']         4.4   \n",
      "3                                    ['Fabric store']         3.3   \n",
      "4                                    ['Fabric store']         4.3   \n",
      "6                                      ['Restaurant']         4.5   \n",
      "13  ['Ski rental service', 'Snowboard rental servi...         5.0   \n",
      "\n",
      "    num_of_reviews price                                              hours  \\\n",
      "2               18  None  [['Thursday', '6:30AM–6PM'], ['Friday', '6:30A...   \n",
      "3                6  None  [['Thursday', '9AM–5PM'], ['Friday', '9AM–5PM'...   \n",
      "4                7  None  [['Thursday', '9AM–5PM'], ['Friday', '9AM–5PM'...   \n",
      "6               18  None  [['Thursday', '11AM–9:30PM'], ['Friday', '11AM...   \n",
      "13              34  None  [['Thursday', '8AM–5PM'], ['Friday', '8AM–5PM'...   \n",
      "\n",
      "                                                 MISC                 state  \\\n",
      "2   {'Service options': ['Takeout', 'Dine-in', 'De...     Open ⋅ Closes 6PM   \n",
      "3   {'Service options': ['In-store shopping'], 'Pa...     Open ⋅ Closes 5PM   \n",
      "4            {'Service options': ['In-store pickup']}     Open ⋅ Closes 5PM   \n",
      "6   {'Service options': ['Outdoor seating', 'Curbs...  Open ⋅ Closes 9:30PM   \n",
      "13  {'Accessibility': ['Wheelchair accessible entr...     Open ⋅ Closes 5PM   \n",
      "\n",
      "                                     relative_results  \\\n",
      "2   ['0x80c2c78249aba68f:0x35bf16ce61be751d', '0x8...   \n",
      "3   ['0x80c2c8811477253f:0x23a8a492df1918f7', '0x8...   \n",
      "4   ['0x80c2c62c496083d1:0xdefa11317fe870a1', '0x8...   \n",
      "6                                                None   \n",
      "13  ['0x80960dcd6ba76731:0x9a6875ced2f9228e', '0x8...   \n",
      "\n",
      "                                                  url  \n",
      "2   https://www.google.com/maps/place//data=!4m2!3...  \n",
      "3   https://www.google.com/maps/place//data=!4m2!3...  \n",
      "4   https://www.google.com/maps/place//data=!4m2!3...  \n",
      "6   https://www.google.com/maps/place//data=!4m2!3...  \n",
      "13  https://www.google.com/maps/place//data=!4m2!3...  \n"
     ]
    }
   ],
   "source": [
    "# Definir los límites geográficos de latitud y longitud para los 4 estados\n",
    "\n",
    "# California\n",
    "lat_min_ca, lat_max_ca = 32.5, 42\n",
    "long_min_ca, long_max_ca = -124.4, -114.1\n",
    "\n",
    "# Florida\n",
    "lat_min_fl, lat_max_fl = 24.5, 31\n",
    "long_min_fl, long_max_fl = -87.6, -80.0\n",
    "\n",
    "# Illinois\n",
    "lat_min_il, lat_max_il = 36.9, 42.5\n",
    "long_min_il, long_max_il = -91.5, -87.0\n",
    "\n",
    "# Nueva York\n",
    "lat_min_ny, lat_max_ny = 40.5, 45\n",
    "long_min_ny, long_max_ny = -79.8, -71.8\n",
    "\n",
    "# Filtrar el DataFrame por los rangos de latitud y longitud de cada estado\n",
    "metadata_4_estados = metadata_g1_google[\n",
    "    ((metadata_g1_google['latitude'] >= lat_min_ca) & (metadata_g1_google['latitude'] <= lat_max_ca) & \n",
    "     (metadata_g1_google['longitude'] >= long_min_ca) & (metadata_g1_google['longitude'] <= long_max_ca)) |\n",
    "    \n",
    "    ((metadata_g1_google['latitude'] >= lat_min_fl) & (metadata_g1_google['latitude'] <= lat_max_fl) & \n",
    "     (metadata_g1_google['longitude'] >= long_min_fl) & (metadata_g1_google['longitude'] <= long_max_fl)) |\n",
    "    \n",
    "    ((metadata_g1_google['latitude'] >= lat_min_il) & (metadata_g1_google['latitude'] <= lat_max_il) & \n",
    "     (metadata_g1_google['longitude'] >= long_min_il) & (metadata_g1_google['longitude'] <= long_max_il)) |\n",
    "    \n",
    "    ((metadata_g1_google['latitude'] >= lat_min_ny) & (metadata_g1_google['latitude'] <= lat_max_ny) & \n",
    "     (metadata_g1_google['longitude'] >= long_min_ny) & (metadata_g1_google['longitude'] <= long_max_ny))\n",
    "]\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame filtrado\n",
    "print(metadata_4_estados.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNA VEZ FILTRADO EL DF DE METADATA POR LOS ESTADOS CON LOS QUE TRABAJAREMOS PROCEDO A FILTRARLO POR LAS CATEGORIAS QUE NOS INTERESAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\1732192138.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_4_estados['category'] = metadata_4_estados['category'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name                                            address  \\\n",
      "6           Vons Chicken  Vons Chicken, 12740 La Mirada Blvd, La Mirada,...   \n",
      "114   Cape Seafood Shack  Cape Seafood Shack, 603 Del Prado Blvd S, Cape...   \n",
      "271  Mariscos el poblano  Mariscos el poblano, 5401-5441 Coliseum Way, O...   \n",
      "296  Annie's Bake Shoppe  Annie's Bake Shoppe, 10331 SW 54th St, Miami, ...   \n",
      "484         Off The Hoof    Off The Hoof, 201 E 4th St, Santa Ana, CA 92701   \n",
      "\n",
      "                                   gmap_id description   latitude   longitude  \\\n",
      "6    0x80dd2b4c8555edb7:0xfc33d65c4bdbef42        None  33.916402 -118.010855   \n",
      "114  0x88db4147b1d9e6f3:0x943dbd10a92ba1b1        None  26.641377  -81.940545   \n",
      "271  0x808f87f90c1f661f:0xf384e804a61e0c0b        None  37.764203 -122.214647   \n",
      "296  0x88d9c754413f6c9d:0x1f93eff5e0ba9c16        None  25.717416  -80.361945   \n",
      "484  0x80dcd95d192d988b:0x68795f58e35bf888        None  33.748329 -117.866045   \n",
      "\n",
      "                        category  avg_rating  num_of_reviews price  \\\n",
      "6                   [Restaurant]         4.5              18  None   \n",
      "114                 [Restaurant]         5.0               1    $$   \n",
      "271                 [Restaurant]         5.0               3  None   \n",
      "296  [Bakery, Gift basket store]         4.3               3  None   \n",
      "484                 [Restaurant]         4.0               3  None   \n",
      "\n",
      "                                                 hours  \\\n",
      "6    [['Thursday', '11AM–9:30PM'], ['Friday', '11AM...   \n",
      "114                                               None   \n",
      "271  [['Thursday', 'Open 24 hours'], ['Friday', '8A...   \n",
      "296  [['Thursday', '10AM–4PM'], ['Friday', '10AM–4P...   \n",
      "484  [['Thursday', '11AM–10PM'], ['Friday', '11AM–1...   \n",
      "\n",
      "                                                  MISC                 state  \\\n",
      "6    {'Service options': ['Outdoor seating', 'Curbs...  Open ⋅ Closes 9:30PM   \n",
      "114  {'Service options': ['Dine-in', 'Delivery'], '...                  None   \n",
      "271  {'Service options': ['Takeout', 'Dine-in'], 'P...    Open ⋅ Closes 12AM   \n",
      "296  {'Service options': ['In-store shopping', 'Tak...     Open ⋅ Closes 4PM   \n",
      "484                  {'Service options': ['Delivery']}    Permanently closed   \n",
      "\n",
      "                                      relative_results  \\\n",
      "6                                                 None   \n",
      "114                                               None   \n",
      "271                                               None   \n",
      "296  ['0x88d9c75ec79f02c5:0xcc673b8b4ac95579', '0x8...   \n",
      "484                                               None   \n",
      "\n",
      "                                                   url  \n",
      "6    https://www.google.com/maps/place//data=!4m2!3...  \n",
      "114  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "271  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "296  https://www.google.com/maps/place//data=!4m2!3...  \n",
      "484  https://www.google.com/maps/place//data=!4m2!3...  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Definir las categorías a filtrar\n",
    "categories = ['restaurant', 'coffee', 'ice cream', 'cocktail bars', 'wine bars',\n",
    "              'sushi bars', 'tea', 'bakery', 'food', 'diner', 'tortilla',\n",
    "              'vegetarian', 'tofu', 'pie', 'soup', 'salad', 'cake', 'donut', \n",
    "              'sandwiches', 'pizza', 'burger', 'hot dog', \n",
    "              'breakfast & brunch', 'restaurants', 'barbeque']\n",
    "\n",
    "# Convertir la columna 'category' de cadena a lista (si está en formato de texto) y manejar None o NaN\n",
    "metadata_4_estados['category'] = metadata_4_estados['category'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Filtrar solo las filas que no tienen valores nulos en 'category'\n",
    "metadata_4_estados = metadata_4_estados[metadata_4_estados['category'].notnull()]\n",
    "\n",
    "# Filtrar el DataFrame por las categorías\n",
    "metadata_filtrada_por_categoria = metadata_4_estados[\n",
    "    metadata_4_estados['category'].apply(lambda cat_list: any(c.lower() in [cat.lower() for cat in cat_list] for c in categories))\n",
    "]\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame filtrado\n",
    "print(metadata_filtrada_por_categoria.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_filtrada_por_categoria.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINAMOS DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_filtrada_por_categoria.drop_duplicates(subset=[col for col in metadata_filtrada_por_categoria.columns if col != 'category'], inplace=True)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_filtrada_por_categoria.dropna(subset=['category', 'latitude', 'longitude'], inplace=True)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  metadata_filtrada_por_categoria['avg_rating'].fillna(metadata_filtrada_por_categoria['avg_rating'].mean(), inplace=True)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_filtrada_por_categoria['avg_rating'].fillna(metadata_filtrada_por_categoria['avg_rating'].mean(), inplace=True)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_filtrada_por_categoria['category'] = metadata_filtrada_por_categoria['category'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\240975181.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_filtrada_por_categoria.rename(columns={'gmap_id': 'google_map_id', 'avg_rating': 'average_rating'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de limpieza completado y archivo guardado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Eliminar duplicados, excluyendo la columna 'category'\n",
    "metadata_filtrada_por_categoria.drop_duplicates(subset=[col for col in metadata_filtrada_por_categoria.columns if col != 'category'], inplace=True)\n",
    "\n",
    "# 2. Manejar valores nulos\n",
    "metadata_filtrada_por_categoria.dropna(subset=['category', 'latitude', 'longitude'], inplace=True)\n",
    "metadata_filtrada_por_categoria['avg_rating'].fillna(metadata_filtrada_por_categoria['avg_rating'].mean(), inplace=True)\n",
    "\n",
    "# 3. Normalizar nombres de columnas\n",
    "metadata_filtrada_por_categoria.columns = metadata_filtrada_por_categoria.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# 4. Convertir 'category' de cadena de texto a lista\n",
    "metadata_filtrada_por_categoria['category'] = metadata_filtrada_por_categoria['category'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# renombrar columnas\n",
    "metadata_filtrada_por_categoria.rename(columns={'gmap_id': 'google_map_id', 'avg_rating': 'average_rating'}, inplace=True)\n",
    "\n",
    "# 7. Reordenar columnas\n",
    "metadata_filtrada_por_categoria = metadata_filtrada_por_categoria[['name','address','google_map_id', 'latitude', 'longitude', 'category', 'average_rating', 'num_of_reviews']]\n",
    "\n",
    "# 8. Guardar los datos limpios\n",
    "metadata_filtrada_por_categoria.to_parquet('METADATA_limpia_65%.parquet', index=False)\n",
    "\n",
    "print(\"Proceso de limpieza completado y archivo guardado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filtrada_por_categoria.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_google.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver todas las columnas del DataFrame\n",
    "print(reviews_google.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas y modificar el DataFrame original\n",
    "reviews_g1_google.drop(['pics', 'resp'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AQUI LO QUE HARE SERA FILTRAR EL DATASET REVIEW POR LA COLUMNA GOOGLE MAP ID DE METADATA PARA QUE SOLO ME QUEDEN LOS DATOS CORRESPIENDIENTES A LOS NEGOCIOS DE COMIDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   user_id                name           time  rating  \\\n",
      "276  117512920579209523537  Katharine Goodenow  1540702471743       5   \n",
      "277  108709033632532241719                 L A  1610762146437       1   \n",
      "295  102702400298447210565    Javier Marroquin  1565472850582       5   \n",
      "296  100226479657326854949       Claudia Lemus  1522820078622       5   \n",
      "300  108053293913290667684     mariela gurrola  1533882974545       2   \n",
      "\n",
      "                                                  text  \\\n",
      "276  Grain free bakery 🙌 So excited 😆 And they have...   \n",
      "277  After a full day of medical appointments and t...   \n",
      "295  Freshly made bolillos on the daily.  I always ...   \n",
      "296  The food is delicious, fresh bolillo and pan d...   \n",
      "300                                               None   \n",
      "\n",
      "                                   gmap_id  \n",
      "276  0x80c2a3adca45eddd:0x4b572a4116f14e79  \n",
      "277  0x80c2a3adca45eddd:0x4b572a4116f14e79  \n",
      "295  0x80c2c8787d72a945:0xa89bf790157c97b3  \n",
      "296  0x80c2c8787d72a945:0xa89bf790157c97b3  \n",
      "300  0x80c2c8787d72a945:0xa89bf790157c97b3  \n"
     ]
    }
   ],
   "source": [
    "# Obtener los gmap_id que están en el DataFrame de metadata\n",
    "gmap_ids_filtrados = metadata_filtrada_por_categoria['google_map_id'].unique()\n",
    "\n",
    "# Filtrar el DataFrame de reviews_google para que solo contenga reseñas de los gmap_id filtrados\n",
    "reviews_filtrados = reviews_g1_google[reviews_g1_google['gmap_id'].isin(gmap_ids_filtrados)]\n",
    "\n",
    "# Mostrar las primeras filas de las reviews filtradas\n",
    "print(reviews_filtrados.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas únicas: 213183\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados en todas las columnas y dejar solo las filas originales\n",
    "reviews_filtrados_unicos = reviews_filtrados.drop_duplicates()\n",
    "\n",
    "# Mostrar la cantidad de filas después de eliminar los duplicados\n",
    "print(f\"Número de filas únicas: {reviews_filtrados_unicos.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui me di cuenta que el dataset reviews contenia muchos valores nulos en la columna text asi que procedi a separar el df reviews en dos uno que contenga reseñas con texto y otro sin texto ya que las que no tienen reseñas en texto si tienen la puntuacion es decir el rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negocios con reseñas de texto: 124299\n",
      "Negocios sin reseñas de texto: 88884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\3609092310.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negocios_sin_texto.drop(columns=['text'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 1. Dividir en dos tablas\n",
    "\n",
    "# Tabla 1: Negocios con reseñas de texto (filas donde 'text' no es nulo)\n",
    "negocios_con_texto = reviews_filtrados_unicos[reviews_filtrados_unicos['text'].notnull()]\n",
    "\n",
    "# Tabla 2: Negocios sin reseñas de texto (filas donde 'text' es nulo)\n",
    "negocios_sin_texto = reviews_filtrados_unicos[reviews_filtrados_unicos['text'].isnull()]\n",
    "\n",
    "# 2. Eliminar la columna 'text' de la tabla negocios_sin_texto\n",
    "negocios_sin_texto.drop(columns=['text'], inplace=True)\n",
    "\n",
    "# Mostrar el número de filas en cada tabla para verificar\n",
    "print(f\"Negocios con reseñas de texto: {negocios_con_texto.shape[0]}\")\n",
    "print(f\"Negocios sin reseñas de texto: {negocios_sin_texto.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276     grain free bakery  so excited  and they have a...\n",
      "277     after a full day of medical appointments and t...\n",
      "295     freshly made bolillos on the daily  i always c...\n",
      "296     the food is delicious fresh bolillo and pan du...\n",
      "383                                             good food\n",
      "385                                        service was ok\n",
      "393     translated by google excellent submarine type ...\n",
      "394     translated by google healthy fast food\\n\\norig...\n",
      "396     translated by google good attention\\n\\norigina...\n",
      "2118    my boyfriend and i loved getting food from her...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Normalización del texto en la columna 'text'\n",
    "\n",
    "# Convertir el texto a minúsculas\n",
    "negocios_con_texto.loc[:, 'text'] = negocios_con_texto['text'].str.lower()\n",
    "\n",
    "# Eliminar caracteres especiales\n",
    "negocios_con_texto.loc[:, 'text'] = negocios_con_texto['text'].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Eliminar espacios extra al principio y al final\n",
    "negocios_con_texto.loc[:, 'text'] = negocios_con_texto['text'].str.strip()\n",
    "\n",
    "# Mostrar una muestra del texto limpio para verificar los cambios\n",
    "print(negocios_con_texto['text'].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negocios con texto - primeras filas:\n",
      "                       time\n",
      "276 2018-10-28 04:54:31.743\n",
      "277 2021-01-16 01:55:46.437\n",
      "295 2019-08-10 21:34:10.582\n",
      "296 2018-04-04 05:34:38.622\n",
      "383 2019-11-21 06:03:05.947\n",
      "\n",
      "Negocios sin texto - primeras filas:\n",
      "                       time\n",
      "300 2018-08-10 06:36:14.545\n",
      "406 2020-08-27 05:27:32.871\n",
      "410 2018-10-03 08:00:40.936\n",
      "424 2017-10-30 01:11:14.811\n",
      "426 2019-09-04 04:22:53.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\1878690489.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negocios_con_texto['time'] = pd.to_datetime(negocios_con_texto['time'], unit='ms')\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\1878690489.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negocios_sin_texto['time'] = pd.to_datetime(negocios_sin_texto['time'], unit='ms')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Convertir la columna 'time' en la tabla de negocios con texto\n",
    "negocios_con_texto['time'] = pd.to_datetime(negocios_con_texto['time'], unit='ms')\n",
    "\n",
    "# 2. Convertir la columna 'time' en la tabla de negocios sin texto\n",
    "negocios_sin_texto['time'] = pd.to_datetime(negocios_sin_texto['time'], unit='ms')\n",
    "\n",
    "# Mostrar las primeras filas de cada tabla para verificar la conversión\n",
    "print(\"Negocios con texto - primeras filas:\")\n",
    "print(negocios_con_texto[['time']].head())\n",
    "\n",
    "print(\"\\nNegocios sin texto - primeras filas:\")\n",
    "print(negocios_sin_texto[['time']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(negocios_con_texto.columns)\n",
    "print(negocios_sin_texto.columns)\n",
    "print(metadata_filtrada_por_categoria.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\2676665148.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negocios_con_texto['time'] = pd.to_datetime(negocios_con_texto['time'], errors='coerce')\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_18156\\2676665148.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negocios_sin_texto['time'] = pd.to_datetime(negocios_sin_texto['time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'time' a formato datetime\n",
    "negocios_con_texto['time'] = pd.to_datetime(negocios_con_texto['time'], errors='coerce')\n",
    "negocios_sin_texto['time'] = pd.to_datetime(negocios_sin_texto['time'], errors='coerce')\n",
    "\n",
    "# Filtrar los negocios con texto desde el año 2016 en adelante\n",
    "negocios_con_texto_filtrados = negocios_con_texto[negocios_con_texto['time'] >= '2016-01-01']\n",
    "\n",
    "# Filtrar los negocios sin texto desde el año 2016 en adelante\n",
    "negocios_sin_texto_filtrados = negocios_sin_texto[negocios_sin_texto['time'] >= '2016-01-01']\n",
    "\n",
    "# Obtener los 'gmap_id' filtrados de ambos datasets\n",
    "gmap_ids_filtrados_con_texto = negocios_con_texto_filtrados['gmap_id'].unique()\n",
    "gmap_ids_filtrados_sin_texto = negocios_sin_texto_filtrados['gmap_id'].unique()\n",
    "\n",
    "# Combinar los 'gmap_id' de ambos datasets en un solo conjunto\n",
    "gmap_ids_filtrados = set(gmap_ids_filtrados_con_texto).union(set(gmap_ids_filtrados_sin_texto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   name  \\\n",
      "6                                          Vons Chicken   \n",
      "742                                             Dunkin'   \n",
      "761                                         La Potranca   \n",
      "904   Gormley's on the river | Modern cuisine in his...   \n",
      "2438                                       Bachata Rosa   \n",
      "\n",
      "                                                address  \\\n",
      "6     Vons Chicken, 12740 La Mirada Blvd, La Mirada,...   \n",
      "742           Dunkin', 4008 Bell Blvd, Queens, NY 11361   \n",
      "761   La Potranca, 12821 Venice Blvd., Los Angeles, ...   \n",
      "904   Gormley's on the river | Modern cuisine in his...   \n",
      "2438    Bachata Rosa, 887w W 29th St, Hialeah, FL 33012   \n",
      "\n",
      "                              google_map_id   latitude   longitude  \\\n",
      "6     0x80dd2b4c8555edb7:0xfc33d65c4bdbef42  33.916402 -118.010855   \n",
      "742   0x89c261f60bdf13db:0x38da730e4687a97b  40.763985  -73.771430   \n",
      "761    0x80c2baf50d29bf63:0x5bd904b842b9fcc  34.000181 -118.441249   \n",
      "904   0x8894b5a7a7909725:0xe4687299fd288188  29.726949  -84.981535   \n",
      "2438  0x88d9ba5d65937567:0xbc27649cf513cc89  25.848173  -80.299773   \n",
      "\n",
      "                                               category  average_rating  \\\n",
      "6                                          [Restaurant]             4.5   \n",
      "742   [Coffee shop, Bagel shop, Bakery, Breakfast re...             3.5   \n",
      "761                                        [Restaurant]             4.2   \n",
      "904              [Modern French restaurant, Restaurant]             4.3   \n",
      "2438                                       [Restaurant]             3.6   \n",
      "\n",
      "      num_of_reviews  \n",
      "6                 18  \n",
      "742                8  \n",
      "761               13  \n",
      "904               17  \n",
      "2438               8  \n"
     ]
    }
   ],
   "source": [
    "# Filtrar el dataset de metadata por los 'gmap_id' filtrados\n",
    "metadata_filtrada_final = metadata_filtrada_por_categoria[metadata_filtrada_por_categoria['google_map_id'].isin(gmap_ids_filtrados)]\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print(metadata_filtrada_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negocios_con_texto_filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negocios_con_texto_filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negocios_sin_texto_filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames guardados exitosamente en la carpeta 'data_limpia_65'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Crear la carpeta 'data_limpia' si no existe\n",
    "output_folder = 'data_limpia_65'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Guardar los DataFrames en formato parquet\n",
    "negocios_con_texto_filtrados.to_parquet(os.path.join(output_folder, 'reviews_negocios_con_texto_filtrados.parquet'))\n",
    "negocios_sin_texto_filtrados.to_parquet(os.path.join(output_folder, 'reviews_negocios_sin_texto_filtrados.parquet'))\n",
    "metadata_filtrada_final.to_parquet(os.path.join(output_folder, 'metadata_filtrada_final.parquet'))\n",
    "\n",
    "print(f\"DataFrames guardados exitosamente en la carpeta '{output_folder}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negocios_con_texto_filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filtrada_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min_ny, lat_max_ny = 40.5, 45\n",
    "long_min_ny, long_max_ny = -79.8, -71.8\n",
    "negocios_nueva_york = metadata_filtrada_final[\n",
    "    (metadata_filtrada_final['latitude'] >= lat_min_ny) &\n",
    "    (metadata_filtrada_final['latitude'] <= lat_max_ny) &\n",
    "    (metadata_filtrada_final['longitude'] >= long_min_ny) &\n",
    "    (metadata_filtrada_final['longitude'] <= long_max_ny)\n",
    "]\n",
    "print(negocios_nueva_york.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_negocios_nueva_york = negocios_nueva_york.shape[0]\n",
    "print(f\"Número de negocios en Nueva York: {conteo_negocios_nueva_york}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
